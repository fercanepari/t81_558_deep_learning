{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANDO DATOS\n",
    "\n",
    "El API de Dataset incluye dos nuevos tipos de objetos: \n",
    "\n",
    "* El tf.data.Dataset:\n",
    "\n",
    " * Creando una fuente/soure (Ej Dataset.from_tensor_slices())\n",
    " * Aplicando transformaciones partir de uno más tf.data.Dataset \n",
    " \n",
    " \n",
    "* El tf.iterator\n",
    "\n",
    "   * One-Shot\n",
    "   * Initializable\n",
    "   * Reinitializable\n",
    "   * feedable\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1  <dtype: 'float32'> , (10,)\n",
      "Dataset 2  (tf.float32, tf.int32) , (TensorShape([]), TensorShape([Dimension(100)]))\n",
      "Dataset 3  (tf.float32, (tf.float32, tf.int32)) , (TensorShape([Dimension(10)]), (TensorShape([]), TensorShape([Dimension(100)])))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sess = tf.Session()\n",
    "\n",
    "dat1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))\n",
    "print(\"Dataset 1 \", dat1.output_types, \",\" ,dat1.output_shapes)  \n",
    "\n",
    "#Diferentes formas\n",
    "dat2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random_uniform([4]),\n",
    "    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "print(\"Dataset 2 \", dat2.output_types, \",\" , dat2.output_shapes)  \n",
    "\n",
    "#Unir dos dataset\n",
    "dat3 = tf.data.Dataset.zip((dat1, dat2))\n",
    "print(\"Dataset 3 \", dat3.output_types, \",\" , dat3.output_shapes)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "#One shot \n",
    "dataset = tf.data.Dataset.range(100) #Metodo que crea un dataset de 100 numero\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "for i in range(94):\n",
    "  sess = tf.Session()\n",
    "  val = sess.run(next_element)\n",
    "  i == val\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos hacer transformaciones sobre un dataset ya existente con :\n",
    "* map(lambda x: ...)\n",
    "* flat_map(lambda x, y: ...)\n",
    "* filter(lambda x, (y, z): ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[4]\n",
      "[6]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "#Vamos a imaginarnos que tenemos un array que convertimos en dataset\n",
    "#Queremos otro dataset que sea el doble del primero\n",
    "x = np.array([[1],[2],[3],[4]])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset2 = dataset.map(lambda x: x*2)\n",
    "\n",
    "iter = dataset2.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        for _ in range(len(x)):\n",
    "            print(sess.run(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Altura', <tf.Tensor 'IteratorGetNext_6:0' shape=(32,) dtype=float32>), ('Peso', <tf.Tensor 'IteratorGetNext_6:1' shape=(32,) dtype=float32>)])\n",
      "[array([6.9, 6.7, 5.1, 5.5, 5. , 5.1, 6.1, 5. , 5.2, 6.5, 4.9, 7.9, 6.6,\n",
      "       6.5, 7.2, 7.7, 6.7, 4.8, 5.9, 5.8, 5. , 5. , 7.7, 7.1, 5.6, 6.1,\n",
      "       4.4, 5.1, 6.2, 5.9, 5.9, 5.8], dtype=float32), array([3.1, 3.3, 3.5, 2.4, 3.3, 3.7, 2.8, 3.4, 3.5, 3. , 3.1, 3.8, 3. ,\n",
      "       2.8, 3.2, 3.8, 3.3, 3.1, 3. , 2.8, 3.6, 2.3, 2.8, 3. , 2.9, 3. ,\n",
      "       3.2, 3.4, 2.9, 3.2, 3. , 2.7], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = '/home/user-es-ubuntu/Escritorio/data/data.csv'\n",
    "dataset = tf.contrib.data.make_csv_dataset(CSV_PATH, batch_size=32)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "next = iter.get_next()\n",
    "print(next) \n",
    "inputs, labels = next['Altura'], next['Peso']\n",
    "with  tf.Session() as sess:\n",
    "    res = sess.run([inputs, labels])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
