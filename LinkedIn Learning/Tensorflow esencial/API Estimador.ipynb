{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Estimator\n",
    "\n",
    "API Estimator es otro API de alto nivel en TensorFlow que simplifica en gran medida la programación.\n",
    "\n",
    "Los estimadores encapsulan:\n",
    "\n",
    "* Definición de modelos\n",
    "\n",
    "```\n",
    "estimator = tf.estimator.LinearRegressor(    \n",
    "        feature_columns=feature_cols ...)\t\n",
    "```\n",
    "\n",
    "* Training\n",
    "\n",
    "```\n",
    "train(input_fn, hooks=None, steps=None, max_steps=None, saving_listeners=None) \t\n",
    "```         \n",
    "Donde input_fn es una función que provee de los datos de la forma (características, etiquetas) respecto los datos de training\n",
    "\n",
    "* Evaluación\n",
    "```\n",
    "evaluate(input_fn, steps=None, hooks=None, checkpoint_path=None, name=None) \n",
    "```\n",
    "\n",
    "Donde input_fn es una función que provee de los datos de la forma (características, etiquetas) respecto a los datos de test\n",
    "\n",
    "* Predicción\n",
    "\n",
    "```\n",
    "predict(input_fn, predict_keys=None, hooks=None, checkpoint_path=None, yield_single_examples=True)\n",
    "```\n",
    "\n",
    "Donde input_fn es una función que construye los datos de la forma (características, etiquetas) \n",
    "Predict_keys es la lista de claves a predecir\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ¿Cómo los usamos?:\n",
    "    \n",
    "#### * Funciones para importar dataset\n",
    "  \n",
    "  De cada dataset debemos obtener dos objetos:\n",
    "  * Un diccionario en el cual las claves son características y valores de los tensores que contienen los datos de esos atributos\n",
    "  * Un tensor que contiene las etiquetas/labels\n",
    "  \n",
    "  Ejemplo de cómo debe estructurarse\n",
    "    ```\n",
    "    def input_fn(dataset):\n",
    "    ...  # transformar el dataset, obtener el diccionario y las características\n",
    "    return feature_dict, label\n",
    "    ```  \n",
    "    \n",
    "#### * Definición de atributos característicos\n",
    "   Cada tf.feature_column identifica el nombre de una de nuestras características/atributos, las columnas de nuestro dataset\n",
    "    \n",
    "    ```\n",
    "    altura = tf.feature_column.numeric_column('altura')\n",
    "    peso = tf.feature_column.numeric_column('peso')\n",
    "    nota_media = tf.feature_column.numeric_column('nota_media', normalizer_fn=lambda x: x - nota_global)\n",
    "    ```\n",
    "\n",
    "#### * Instanciar el estimador prefabricado\n",
    "   Veamos un ejemplo con el estimador LinearClassifier\n",
    "   \n",
    "    ```\n",
    "    estimator = tf.estimator.LinearClassifier(\n",
    "        feature_columns=[altura, peso, nota_media])\n",
    "     ```\n",
    "    \n",
    "#### * Llamar al método de training, evaluate o predict\n",
    "   Definimos para por ejemplo el training la entrada a la función de importar datos\n",
    "   \n",
    "   ```   \n",
    "   estimator.train(input_fn=my_training_set, steps=2000)\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n",
      "W0829 18:39:24.505276 139816252819264 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp_tb70roi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creado estimador\n",
      "\n",
      "Test set accuracy: 0.867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de una regresión lineal\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "train_data = pd.read_csv(\"/home/user-es-ubuntu/Escritorio/data/iris_train.csv\", names=['f1', 'f2', 'f3', 'f4', 'f5'])\n",
    "test_data = pd.read_csv(\"/home/user-es-ubuntu/Escritorio/data/iris_test.csv\", names=['f1', 'f2', 'f3', 'f4', 'f5'])\n",
    "\n",
    "train_x = train_data[['f1', 'f2', 'f3','f4']]\n",
    "train_y = train_data.ix[:, 'f5']\n",
    "\n",
    "test_x = test_data[['f1', 'f2', 'f3', 'f4']]\n",
    "test_y = test_data.ix[:, 'f5']\n",
    "\n",
    "train_data.dtypes\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column(key=key) for key in train_x.keys()]\n",
    "\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns, n_classes=3)\n",
    "\n",
    "print(\"creado estimador\")\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: train_input_fn(train_x, train_y, 50),\n",
    "    steps=2000)\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    features = dict(features)\n",
    "    inputs = (features, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: eval_input_fn(test_x, test_y, 100))\n",
    "\n",
    "print('\\Accuracy del modelo: {:0.3f}\\n'.format(**eval_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
