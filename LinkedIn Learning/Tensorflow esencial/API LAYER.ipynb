{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API LAYERS: TFLEARN\n",
    "\n",
    "Tflearn es un paquete del api de alto nivel que nos permite crear capas en nuestros modelos\n",
    "\n",
    "TFLEARN es diferente del paquete tf.learn, para utilizarlo hay que instalar el paquete desde pip3\n",
    "\n",
    "> pip3 install tflearn\n",
    "\n",
    "\n",
    "## ¿Cómo se usa?\n",
    "\n",
    "* Crea una capa tipo input al inicio\n",
    "\n",
    "    capa_init = tflearn.input_data(shape=[None, 2], name=\"entrada\")\n",
    "\n",
    "* Pasa el objeto input a las capas más adelante\n",
    "\n",
    "     capa1 = tflearn.X(capa_init,...)\n",
    "     \n",
    "\n",
    "* Añade las capas que quieras hasta la de salida\n",
    "\n",
    "* Crea una red usando un estimator \n",
    "\n",
    "   mired=tflearn.regression(capaSalida,\n",
    "   \n",
    "                         optimizer='sgd',\n",
    "                         \n",
    "                         learning_rate= 2.,\n",
    "                         \n",
    "                         loss='binary_crossentropy'\n",
    "                         \n",
    "                        )\n",
    "                        \n",
    "* Creamos el modelo:\n",
    "\n",
    "    model=tflearn.DNN(miRed)\n",
    "    \n",
    "* Entrena el modelo:\n",
    "\n",
    "    model.fit(X, y, n_epoch=10)\n",
    "\n",
    "* Evaluar modelo\n",
    "\n",
    "    model.evaluate(np.array(X_test), np.array(Y_test))\n",
    "\n",
    "* Predecir\n",
    "\n",
    "     model.predict(nuevaEntrada)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Tipos de capas\n",
    "\n",
    "Existen diferentes modelos de capas dentro del módulo de tflearn.layers.core\n",
    "\n",
    "\n",
    "|Clase de capa\t|Descripción|\n",
    "| ---------- | ---------- |\n",
    "input_data\t|Capa de entrada a la red de datos|\n",
    "|fully_connected\t|Este tipo de capa interconecta todas las neuronas con todas las de la capa previa|\n",
    "|dropout\t|Esta capa se utiliza para la regularización del dropout|\n",
    "|custom_layer\t|Esta capa la utilizamos cuando queremos especificar una función personalizada a la entrada|\n",
    "|reshape\t|Esta capa cambia la forma la entrada según una salida específica |\n",
    "|flatten\t|Esta capa convierte el tensor de entrada en un tensor 2D|\n",
    "|activation\t|Esta capa aplica la función de activación especificada al tensor de entrada|\n",
    "|single_unit\t|Esta capa aplica la función lineal a las entradas|\n",
    "|highway\t|Esta capa implementa la función de highway totalmente conectada|\n",
    "|one_hot_encoding\t|Esta capa convierte las etiquetas numéricas en sus representaciones codificadas en caliente de un vector binario|\n",
    "|time_distributed\t|Esta capa aplica la función especifica en cada instante al tensor de entrada|\n",
    "|multi_target_data\t|Esta capa crea y concatena múltiples placeholders|\n",
    "\n",
    "\n",
    "También ofrece capas para redes convolucionales, algunas son:\n",
    "\n",
    "\n",
    "|Clase de capa\t|Descripción|\n",
    "| ---------- | ---------- |\n",
    "|conv_1d\t|Esta capa aplica una convolución 1D sobre la entrada |\n",
    "|conv_2d\t|Esta capa aplica una convolución 2D sobre la entrada |\n",
    "|conv_3d\t|Esta capa aplica una convolución 3D sobre la entrada |\n",
    "|conv_2d_transpose\t|Esta capa aplica una transpuesta de conv2_d a la entrada |\n",
    "|conv_3d_transpose\t|Esta capa aplica una transpuesta de conv3_d a la entrada  |\n",
    "|atrous_conv_2d\t|Esta capa calcula una convolución atrous en 2-D |\n",
    "|grouped_conv_2d\t|Esta capa calcula una convolución 2D en profundidad |\n",
    "|max_pool_1d\t|Esta capa calcula 1-D max pooling |\n",
    "|max_pool_2d\t|Esta capa calcula 2D max pooling |\n",
    "|avg_pool_1d\t|Esta capa calcula 1D pooling promedio |\n",
    "|avg_pool_2d\t|Esta capa calcula 2D pooling promedio  |\n",
    "\n",
    "\n",
    "Y también para redes recurrentes tenemos capas\n",
    "\n",
    "|Clase de capa\t|Descripción|\n",
    "| ---------- | ---------- |\n",
    "|simple_rnn\t|Esta capa implementa el modelo de red neuronal recurrente simple|\n",
    "|bidirectional_rnn\t|Esta capa implementa el modelo de red neuronal Bidireccional|\n",
    "|lstm\t|Esta capa implementa el modelo LSTM|\n",
    "|gru |Esta capa implementa el modelo de red neuronal GRU|\n",
    "\n",
    "\n",
    "Sobre estimadores ofrece el estimador de regression con distintos optimizadores:\n",
    "\n",
    "* SGD\n",
    "* RMSprop\n",
    "* Adam\n",
    "* Momentum\n",
    "* AdaGrad\n",
    "* Ftrl\n",
    "* AdaDelta\n",
    "* ProximalAdaGrad\n",
    "* Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: J5BLYG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.096s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.50694\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 002 | loss: 0.50694 - binary_acc: 0.6750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.55302\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.55302 - binary_acc: 0.7364 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.56070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 004 | loss: 0.56070 - binary_acc: 0.7466 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.56247\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 005 | loss: 0.56247 - binary_acc: 0.7490 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.56298\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 006 | loss: 0.56298 - binary_acc: 0.7496 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.56315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 007 | loss: 0.56315 - binary_acc: 0.7499 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.56321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 008 | loss: 0.56321 - binary_acc: 0.7499 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.56324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 009 | loss: 0.56324 - binary_acc: 0.7500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.56325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 010 | loss: 0.56325 - binary_acc: 0.7500 -- iter: 4/4\n",
      "--\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tflearn\n",
    "import numpy as np\n",
    "\n",
    "X_train = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "y_train = [[1.], [1.], [1.], [0.]]\n",
    "\n",
    "X_test = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y_test = [[1], [1], [1], [0]]\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    #Creamos una capa de layer inicial con el comando tflearn.input\n",
    "    capa_init = tflearn.input_data(shape=[None, 2], name=\"x\")\n",
    "    #Creamos capas intermedias y las conectamos, existen diferentes tipos de capas, vamos a utilizar fully\n",
    "    capa1 = tflearn.fully_connected(capa_init, 10, activation=\"relu\")\n",
    "    capa2 = tflearn.fully_connected(capa1, 10, activation= \"relu\")\n",
    "    #Creamos la capa salida con su función de activación softmax\n",
    "    salida = tflearn.fully_connected(capa2, 1, activation=\"softmax\")\n",
    "    #Creamos la red para la capa de estimador, en este caso una regresión\n",
    "    #utlizamos el comando tflearn.regression\n",
    "    miRed = tflearn.regression(salida,\n",
    "                         optimizer='sgd',\n",
    "                         learning_rate= 2.,\n",
    "                         loss='binary_crossentropy'\n",
    "                        )\n",
    "\n",
    "    model=tflearn.DNN(miRed)\n",
    "    model.fit(X_train, y_train, n_epoch=10, show_metric=True)\n",
    "    score = model.evaluate(np.array(X_test), np.array(Y_test), batch_size=128)\n",
    "    print('Test accuracy:', score[0])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "a = model.predict([[0., 0.]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
